{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset-f\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.io import wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "%autoreload\n",
    "from res_ind_lib import *\n",
    "import os, time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\",category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  from the world bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_weeks = (time.time()-os.stat(\"wb_data.csv\").st_mtime )/(3600*24*7)\n",
    "if nb_weeks>10: \n",
    "    warnings.warn(\"World bank data are \"+str(int(nb_weeks))+\" weeks old. You may want to download them again.\")\n",
    "df=pd.read_csv(\"wb_data.csv\").set_index(\"country\")\n",
    "df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Income gorups for countries and HIPC status\n",
    "groups = pd.read_csv(\"income_groups.csv\",header =4,index_col=2).replace({\"ROM\":\"ROU\",\"ZAR\":\"COD\"})  #they used old iso3 country for Zair (Congo) and Romania\n",
    "groups= groups[[\"Code\",\"Region\",\"Income group\",\"Lending category\",\"Other\"]]\n",
    "groups.dropna(axis=0,how=\"all\",inplace=True);\n",
    "groups.rename(columns={\"Other\":\"HIPC\"},inplace=True)\n",
    "groups['HIPC'].fillna('norm',inplace=True)\n",
    "groups[\"Lending category\"].replace(\"..\",\"\",inplace=True)\n",
    "\n",
    "df[\"iso3\"]=groups[\"Code\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def names_to_wb_name(df_in,any_name_to_iso3,iso3_to_unique_name,common_name=\"iso3\",end_name=\"country\"):\n",
    "    \"\"\"Matches arbitrary country names from a dataset to world bank country names thru iso3 codes\"\"\"\n",
    "    \n",
    "    df=pd.DataFrame(df_in)\n",
    "    \n",
    "    index_name=df.index.name\n",
    "    \n",
    "    df[common_name]=any_name_to_iso3[common_name]\n",
    "    \n",
    "    #warns and prints if some countries are not recognized\n",
    "    cond = df[common_name].isnull()\n",
    "    if cond.sum()>0:\n",
    "        warnings.warn(\"Unrecognized countries in 1st argument 'df':\"+\", \".join((df.index[cond].values)))\n",
    "        warnings.warn(\"Correct 'df' or add lines to 2nd argument 'any_name_to_iso3'\")\n",
    "    \n",
    "    df=df.dropna()\n",
    "    \n",
    "    #warning if missing\n",
    "    df =df.reset_index().set_index(common_name)\n",
    "    df[end_name]=iso3_to_unique_name\n",
    "    cond = df[end_name].isnull()\n",
    "    if cond.sum()>0:\n",
    "        warnings.warn(\"this countries appear to be missing from 3rd argument 'iso3_to_unique_name':\"+\", \".join((df.index[cond])))\n",
    "\n",
    "           \n",
    "    #return df with original indexing\n",
    "    return df.dropna().set_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# share of poor individuals, we chose the bottom 20\n",
    "ph=df[\"pov_head\"]=0.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gets hfa data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# READ THE LAST HFA DATA\n",
    "hfa_newest =   pd.read_csv(\"HFA_all_2011_2013.csv\").rename(columns={\"ISO 3\":\"iso3\",\"Country name\":\"country\"}).set_index(\"country\")\n",
    "\n",
    "# READ THE PREVIOUS HFA DATA\n",
    "hfa_previous = pd.read_csv(\"HFA_all_2009_2011.csv\").rename(columns={\"ISO 3\":\"iso3\",\"Country name\":\"country\"}).set_index(\"country\")\n",
    "\n",
    "#most recent values... if no 2011-2013 reporting, we use 2009-2011\n",
    "hfa=hfa_newest.fillna(hfa_previous)\n",
    "\n",
    "# access to early warning = priority for action 2, indicator 3 of the HFA\n",
    "hfa[\"shew\"]=1/5*hfa[\"P2-C3\"] # between zero and 1. \n",
    "\n",
    "# ability to scale up = average of priority for action 5 of the HFA\n",
    "#hfa[\"prepare_scaleup_old\"]=(hfa[\"P5-C1\"]+hfa[\"P5-C2\"]+hfa[\"P5-C4\"])/3/5 # between zero and 1\n",
    "hfa[\"prepare_scaleup\"]=(hfa[\"P4-C2\"]+hfa[\"P5-C2\"]+hfa[\"P4-C5\"])/3/5 # between zero and 1\n",
    "hfa[\"finance_pre\"] = hfa[\"P5-C3\"]/5 #betwenn 0 and 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches names with wb names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this table matches country names rendered in several ways to their actual iso2 and iso3 codes\n",
    "any_name_to_iso3 =pd.read_csv(\"names_to_iso.csv\").set_index(\"country\")\n",
    "#this tables has WB country names and iso3 countries\n",
    "iso3_to_unique_name = pd.read_csv(\"iso3_to_wb_name.csv\").set_index(\"iso3\")\n",
    "\n",
    "#matches names in HFA to  names\n",
    "df[[\"shew\",\"prepare_scaleup\",\"finance_pre\"]]= names_to_wb_name(hfa[[\"shew\",\"prepare_scaleup\",\"finance_pre\"]],any_name_to_iso3,iso3_to_unique_name) \n",
    "\n",
    "# Assumes that no HFA reporting means no preparation\n",
    "df[[\"shew\",\"prepare_scaleup\",\"finance_pre\"]] = df[[\"shew\",\"prepare_scaleup\",\"finance_pre\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EUsilc and other countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "silc = pd.read_csv(\"social_ratios.csv\")\n",
    "#EU cuntry code to iso2 \n",
    "silc[\"iso2\"]=silc[\"cc\"].replace({\"EL\":\"GR\",\"UK\":\"GB\"}) #Greece and UK\n",
    "silc.set_index(\"iso2\",inplace=True)\n",
    "\n",
    "#iso3 to wb country name table\n",
    "iso3_to_wb=pd.read_csv(\"iso3_to_wb_name.csv\").set_index(\"iso3\")\n",
    "\n",
    "#iso2 to iso3 table\n",
    "iso2_iso3 = pd.read_csv(\"names_to_iso.csv\")[[\"iso2\",\"iso3\"]].drop_duplicates().set_index(\"iso3\") #the tables has more lines than countries to account for several ways of writing country names\n",
    "\n",
    "#iso2 to WB \n",
    "iso2_iso3[\"country\"]=iso3_to_wb[\"country\"]\n",
    "iso2_country=iso2_iso3.reset_index().set_index(\"iso2\")\n",
    "\n",
    "#indexes this data by WB country\n",
    "silc[\"country\"]=iso2_country[\"country\"]\n",
    "silc.set_index(\"country\",inplace=True)\n",
    "#silc.drop_duplicates(inplace=True)\n",
    "\n",
    "#Monitoring differences between SILC and ASPIRE\n",
    "hop=df.ix[silc.index,[\"social_p\",\"social_r\"]].dropna().rename(columns=dict(social_p = \"s_p_aspire\", social_r=\"s_r_aspire\"))\n",
    "hop[[\"sp_silc\",\"sr_silc\"]]= silc.ix[hop.index,[\"social_p\",\"social_r\"]]\n",
    "#plt.scatter(x=hop.sp_silc,y=hop.s_p_aspire), plt.scatter(x=hop.sr_silc,y=hop.s_r_aspire,c=\"red\")\n",
    "\n",
    "df.ix[silc.index,[\"social_p\",\"social_r\"]]=silc[[\"social_p\",\"social_r\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:5: UserWarning: Credit ratings are 4 weeks old. Get new ones at http://www.tradingeconomics.com/country-list/rating\n"
     ]
    }
   ],
   "source": [
    "#Reads the data and check its not too old\n",
    "the_credit_rating_file =\"cred_rat.csv\"\n",
    "nb_weeks = (time.time()-os.stat(the_credit_rating_file).st_mtime )/(3600*24*7)\n",
    "if nb_weeks>3: \n",
    "    warnings.warn(\"Credit ratings are \"+str(int(nb_weeks))+\" weeks old. Get new ones at http://www.tradingeconomics.com/country-list/rating\")\n",
    "ratings_raw  =pd.read_csv(the_credit_rating_file,dtype=\"str\").dropna(how=\"all\")\n",
    "ratings_raw=ratings_raw.rename(columns={\"Unnamed: 0\": \"country_in_ratings\"}).set_index(\"country_in_ratings\")[[\"S&P\",\"Moody's\",\"Fitch\"]]\n",
    "ratings_raw.rename(index=str.strip,inplace=True)\n",
    "\n",
    "#this table matches country names rendered in several ways to their actual iso2 and iso3 codes\n",
    "names_to_iso =pd.read_csv(\"names_to_iso.csv\").set_index(\"country\")\n",
    "\n",
    "#this tables has WB country names and iso3 countries\n",
    "iso_country = pd.read_csv(\"iso3_to_wb_name.csv\").set_index(\"iso3\")\n",
    "\n",
    "ratings_raw =  names_to_wb_name(ratings_raw,names_to_iso,iso_country)\n",
    "#ratings_raw=ratings_raw.reset_index().set_index(\"country\")\n",
    "\n",
    "def mystriper(string):\n",
    "    \"\"\"strip blanks and converts everythng to lower case\"\"\"\n",
    "    if type(string)==str:\n",
    "        return str.strip(string).lower()\n",
    "    else:\n",
    "        return string\n",
    "        \n",
    "#to lower case and strips blanks\n",
    "ratings_raw=ratings_raw.applymap(mystriper)    \n",
    "\n",
    "#Transforms ratings letters into 1-100 numbers\n",
    "rat_disc = pd.read_csv(\"cred_rat_dict.csv\")\n",
    "ratings=ratings_raw\n",
    "ratings[\"S&P\"].replace(rat_disc[\"s&p\"].values,rat_disc[\"s&p_score\"].values,inplace=True)\n",
    "ratings[\"Moody's\"].replace(rat_disc[\"moodys\"].values,rat_disc[\"moodys_score\"].values,inplace=True)\n",
    "ratings[\"Fitch\"].replace(rat_disc[\"fitch\"].values,rat_disc[\"fitch_score\"].values,inplace=True)\n",
    "df[\"rating\"]=ratings.mean(axis=1)/100\n",
    "\n",
    "df[\"rating\"].fillna(0,inplace=True)  #assumes no rating is bad rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data arranged from Penn tables\n",
    "k_data=pd.read_csv(\"capital_data.csv\")[[\"code\",\"cgdpo\",\"ck\"]].replace({\"ROM\":\"ROU\",\"ZAR\":\"COD\"}).rename(columns={\"cgdpo\":\"prod_from_k\",\"ck\":\"k\"})#Zair is congo\n",
    "\n",
    "#matches names in the dataset with world bank country names\n",
    "iso_country = pd.read_csv(\"iso3_to_wb_name.csv\").set_index(\"iso3\")\n",
    "k_data.set_index(\"code\",inplace=True)\n",
    "k_data[\"country\"]=iso_country[\"country\"]\n",
    "cond = k_data[\"country\"].isnull()\n",
    "if cond.sum()>0:\n",
    "     warnings.warn(\"this countries appear to be missing from iso3_to_wb_name.csv: \"+\" , \".join(k_data.index[cond].values))\n",
    "k_data=k_data.reset_index().set_index(\"country\")\n",
    "\n",
    "# average productivity of capital\n",
    "df[\"avg_prod_k\"]=k_data[\"prod_from_k\"]/k_data[\"k\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hazard (protection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assumed a function of the income group\n",
    "protection_assumptions = pd.read_csv(\"protection_level_assumptions.csv\").set_index(\"Income group\")\n",
    "df[\"protection\"]=groups[\"Income group\"].replace(protection_assumptions[\"protection\"].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exposure (population in flood-prone areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Esposure data \n",
    "expo = pd.read_csv(\"people_affected_flood.csv\").set_index(\"ISO\")[[\"people_affected_RP10flood_percent\"]]\n",
    "\n",
    "iso3_to_wb_name = pd.read_csv(\"iso3_to_wb_name.csv\").set_index(\"iso3\")\n",
    "expo[\"country\"]=iso3_to_wb_name[\"country\"]\n",
    "\n",
    "df[\"faref\"]=df[\"fa\"]=expo.reset_index().dropna().set_index(\"country\")[[\"people_affected_RP10flood_percent\"]].dropna()\n",
    "\n",
    "#Exposure bias\n",
    "pe=df[\"peref\"] =df[\"pe\"]=.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:8: UserWarning: this countries appear to be missing from iso3_to_wb_name.csv: ALA , ATA , BES , BVT , IOT , CXR , CCK , FLK , GUF , ATF , GIB , GLP , GGY , HMD , VAT , JEY , MTQ , MYT , MSR , NFK , PCN , REU , BLM , SHN , SPM , SGS , SJM , TKL , UMI , WLF , ESH.\n",
      "These are: Aland Islands , Antarctica , Bonaire , Bouvet Island , British Indian Ocean Territory , Christmas Island , the Cocos (Keeling) Islands , the Falkland Islands (Malvinas) , French Guiana , the French Southern Territories , Gibraltar , Guadeloupe , Guernsey , Heard Island and McDonald Islands , the Holy See (Vatican City State) , Jersey , Martinique , Mayotte , Montserrat , Norfolk Island , Pitcairn , Reunion , Saint Barthelemy , Saint Helena , Saint Pierre and Miquelon , South Georgia and the South Sandwich Islands , Svalbard and Jan Mayen , Tokelau , the United States Minor Outlying Islands , Wallis and Futuna , Western Sahara\n"
     ]
    }
   ],
   "source": [
    "#Reads data from pager\n",
    "pager=pd.read_csv(\"pager_vulnerabilities.csv\")[[\"ISO-3digit\",\"R_1\",\"R_2\",\"R_3\",\"VV_1\",\"VV_2\",\"VV_3\",\"Country Name\"]].set_index(\"ISO-3digit\")\n",
    "\n",
    "#indexes pager data by country        \n",
    "pager[\"country\"]=iso3_to_wb_name[\"country\"]\n",
    "cond = pager[\"country\"].isnull()\n",
    "if cond.sum()>0:\n",
    "     warnings.warn(\"this countries appear to be missing from iso3_to_wb_name.csv: \"+\" , \".join(pager.index[cond].values)+\".\\nThese are: \"+\" , \".join(pager.ix[cond,\"Country Name\"].values) )\n",
    "pager[\"country\"]=iso3_to_wb_name[\"country\"]\n",
    "hop=pager.dropna().reset_index().set_index(\"country\")\n",
    "\n",
    "#sorts vulnerabilites according to income\n",
    "share =hop[[\"R_1\",\"R_2\",\"R_3\"]]\n",
    "damrat=hop[[\"VV_1\",\"VV_2\",\"VV_3\"]]\n",
    "\n",
    "damrat.columns=[\"R_1\",\"R_2\",\"R_3\"]\n",
    "p=(share.cumsum(axis=1)-.20)\n",
    "p[p<0]=0\n",
    "poor=share-p\n",
    "poor[poor<0]=0\n",
    "\n",
    "vp=(poor*damrat).sum(axis=1)/poor.sum(axis=1)\n",
    "rich=share-poor\n",
    "\n",
    "vr=(rich*damrat).sum(axis=1)/rich.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Expresses vulnerability as total and bias\n",
    "\n",
    "fa=df[\"fa\"]\n",
    "pe=df[\"peref\"] =df[\"pe\"]\n",
    "fap=fa*(1+pe)\n",
    "far=(fa-ph*fap)/(1-ph)\n",
    "\n",
    "df[\"share1_ref\"]=df[\"share1\"]\n",
    "cp=   df[\"share1\"] /.2*df[\"gdp_pc_pp\"]\n",
    "cr=(1-df[\"share1\"])/.8*df[\"gdp_pc_pp\"]\n",
    "\n",
    "df[\"v\"]  = (ph*vp*cp*fap + (1-ph)*vr*cr*far)/(ph*cp*fap + (1-ph)*cr*far)\n",
    "df[\"pv\"] =  vp/df.v-1\n",
    "\n",
    "#vulnerability of diversified (shared) capital\n",
    "df[\"v_s\"]=vr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Homogenity of losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resds loss distribution in mumbai\n",
    "hop=pd.read_csv(\"losses_distribution_mumbai.csv\",index_col=0)[\"losses/asset_cost\"]\n",
    "# standard deviation of the underlying normal distribution\n",
    "s = np.log(hop).std() \n",
    "\n",
    "df[\"H\"]= np.exp (-s**2/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report missing data for the national studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_missing</th>\n",
       "      <th>missing_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nicaragua</th>\n",
       "      <td>1</td>\n",
       "      <td>avg_prod_k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Djibouti</th>\n",
       "      <td>1</td>\n",
       "      <td>unemp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Togo</th>\n",
       "      <td>1</td>\n",
       "      <td>social_p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>1</td>\n",
       "      <td>plgp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>2</td>\n",
       "      <td>plgp, avg_prod_k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nb_missing      missing_data\n",
       "country                                  \n",
       "Nicaragua             1        avg_prod_k\n",
       "Djibouti              1             unemp\n",
       "Togo                  1          social_p\n",
       "Iraq                  1              plgp\n",
       "Afghanistan           2  plgp, avg_prod_k"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_missing_data(s):\n",
    "    which = s[s.isnull()].index.values\n",
    "    return \", \".join(which)\n",
    "\n",
    "def count_missing_data(s):\n",
    "    return s.isnull().sum()\n",
    "\n",
    "report = pd.DataFrame()\n",
    "\n",
    "report[\"nb_missing\"]=df.apply(count_missing_data,axis=1)  \n",
    "report[\"missing_data\"]=df.apply(write_missing_data,axis=1)\n",
    "\n",
    "report  = report.ix[report[\"nb_missing\"]>0,:]\n",
    "report.sort(columns=\"nb_missing\",inplace=True)\n",
    "report.to_csv(\"missing_data_report.csv\")\n",
    "\n",
    "report.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no ripple effects\n",
    "df[\"alpha\"] =0 \n",
    "\n",
    "#Reconstruction time\n",
    "df[\"T_rebuild_K\"] = 3\n",
    "df[\"T_rebuild_L\"] = 40\n",
    "\n",
    "# how much early warning reduces vulnerability\n",
    "df[\"pi\"] = 0.2\n",
    "\n",
    "#income elasticity\n",
    "df[\"income_elast\"] = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##sensitivity anlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"original_country\"]=df.index;\n",
    "\n",
    "country_sens_list=[\"Malawi\",\"Sweden\"]\n",
    "#reads paramters to be varied\n",
    "alt_params=pd.read_csv(\"alt_params.csv\")\n",
    "\n",
    "df_sensit = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for c in country_sens_list:\n",
    "    for p in alt_params.index.tolist():\n",
    "        param = alt_params.ix[p,\"param\"]\n",
    "        new_value = alt_params.ix[p,\"value\"]\n",
    "        d = c+\" $(\"+alt_params.ix[p,\"formated_name\"]+\"=\"+str(new_value)+\")$\"\n",
    "        df_sensit.ix[d] = df.ix[c]\n",
    "        df_sensit.ix[d,param] =new_value\n",
    "        df_sensit.ix[d,\"original_country\"]=c\n",
    "        \n",
    "'''for c in df.index:\n",
    "    for param in [\"income_elast\"]:\n",
    "        for new_value in [1, 2]:\n",
    "            d = c+\"_\"+param+\"_\"+str(new_value)\n",
    "            df_sensit.ix[d] = df.ix[c]\n",
    "            df_sensit.ix[d,param] =new_value\n",
    "            df_sensit.ix[d,\"original_country\"]=c '''\n",
    "\n",
    "df_sensit.index.name=\"country\"; #after adding indices pandas forgets their name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computes and saves national resilience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saves orginal dataframe before adding columns with results\n",
    "df.drop(\"iso3\", axis=1).to_csv(\"df_original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb countries with all data :90\n",
      "nb countries with all data and results :90\n"
     ]
    }
   ],
   "source": [
    "df_with_results=compute_resiliences(df)\n",
    "print(\"nb countries with all data :\"+str(df.dropna().shape[0]))\n",
    "print(\"nb countries with all data and results :\"+str(df_with_results[\"resilience\"].dropna().shape[0]))\n",
    "df_with_results.to_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensititvity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sensit.drop(\"iso3\", axis=1).to_csv(\"df_sensit_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_resiliences(df_sensit).to_csv(\"df_sensit_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.669693906030894, 57.97149126008749, 81.279007359104355)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some stats\n",
    "a=df_with_results.resilience;\n",
    "a.min()*100,a.mean()*100,a.max()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Outputs table with main results\n",
    "to_output = ['gdp_pc_pp', 'pop',\"protection\",\"fa\",\"v\",\"resilience\",\"risk\"]\n",
    "a=df_with_results[to_output]\n",
    "a.loc[:,[\"fa\",\"v\",\"resilience\",\"risk\"]]=100*a.loc[:,[\"fa\",\"v\",\"resilience\",\"risk\"]]\n",
    "desc=pd.read_csv(\"inputs_info.csv\").set_index('key')[\"descriptor\"]\n",
    "a.rename(columns=desc.to_dict()).dropna().to_excel(\"results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Ex post studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reads the data\n",
    "expost = pd.read_csv(\"expost_studies.csv\").set_index(\"place\")\n",
    "\n",
    "#fills the altnerative lines with default values\n",
    "expost_filled = expost.fillna( value=expost.ix[\"Mumbai\"],axis=0)\n",
    "\n",
    "#Computes resilience\n",
    "ep=compute_resiliences(expost_filled,kind=\"ex-post\")\n",
    "\n",
    "#Report\n",
    "ep[expost.columns]=expost\n",
    "ep.to_csv(\"expost_studies_with_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>resilience</td>    <th>  R-squared:         </th> <td>   0.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   42.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 May 2015</td> <th>  Prob (F-statistic):</th> <td>1.10e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:45:22</td>     <th>  Log-Likelihood:    </th> <td>  163.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>  -288.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    71</td>      <th>  BIC:               </th> <td>  -240.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    0.4198</td> <td>    0.056</td> <td>    7.542</td> <td> 0.000</td> <td>    0.309     0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_prod_k</th>      <td>   -0.4131</td> <td>    0.046</td> <td>   -8.989</td> <td> 0.000</td> <td>   -0.505    -0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>axfin_p</th>         <td>   -0.0479</td> <td>    0.103</td> <td>   -0.463</td> <td> 0.645</td> <td>   -0.254     0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>axfin_r</th>         <td>    0.0756</td> <td>    0.082</td> <td>    0.922</td> <td> 0.360</td> <td>   -0.088     0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>axhealth</th>        <td>   -0.0751</td> <td>    0.054</td> <td>   -1.383</td> <td> 0.171</td> <td>   -0.183     0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fa</th>              <td>    0.1102</td> <td>    0.115</td> <td>    0.959</td> <td> 0.341</td> <td>   -0.119     0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>finance_pre</th>     <td>    0.0115</td> <td>    0.050</td> <td>    0.230</td> <td> 0.819</td> <td>   -0.088     0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gdp_pc_pp</th>       <td>-1.173e-06</td> <td> 1.33e-06</td> <td>   -0.880</td> <td> 0.382</td> <td>-3.83e-06  1.49e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pe</th>              <td>    0.0840</td> <td>    0.011</td> <td>    7.542</td> <td> 0.000</td> <td>    0.062     0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plgp</th>            <td>    0.1091</td> <td>    0.044</td> <td>    2.463</td> <td> 0.016</td> <td>    0.021     0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prepare_scaleup</th> <td>    0.0696</td> <td>    0.049</td> <td>    1.419</td> <td> 0.160</td> <td>   -0.028     0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>protection</th>      <td>    0.0001</td> <td>    0.000</td> <td>    0.362</td> <td> 0.718</td> <td>   -0.001     0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pv</th>              <td>   -0.0482</td> <td>    0.008</td> <td>   -6.260</td> <td> 0.000</td> <td>   -0.064    -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>          <td>    0.0358</td> <td>    0.031</td> <td>    1.145</td> <td> 0.256</td> <td>   -0.027     0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>share1</th>          <td>    2.2705</td> <td>    0.345</td> <td>    6.588</td> <td> 0.000</td> <td>    1.583     2.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shew</th>            <td>   -0.0184</td> <td>    0.042</td> <td>   -0.441</td> <td> 0.661</td> <td>   -0.102     0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>social_p</th>        <td>    0.1889</td> <td>    0.036</td> <td>    5.231</td> <td> 0.000</td> <td>    0.117     0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>social_r</th>        <td>    0.1141</td> <td>    0.059</td> <td>    1.942</td> <td> 0.056</td> <td>   -0.003     0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemp</th>           <td>    0.0594</td> <td>    0.100</td> <td>    0.595</td> <td> 0.554</td> <td>   -0.140     0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>v</th>               <td>   -0.0007</td> <td>    0.043</td> <td>   -0.016</td> <td> 0.988</td> <td>   -0.087     0.086</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.143</td> <th>  Durbin-Watson:     </th> <td>   2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.833</td> <th>  Prob(JB):          </th> <td>8.17e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.498</td> <th>  Cond. No.          </th> <td>2.29e+22</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             resilience   R-squared:                       0.914\n",
       "Model:                            OLS   Adj. R-squared:                  0.892\n",
       "Method:                 Least Squares   F-statistic:                     42.03\n",
       "Date:                Tue, 12 May 2015   Prob (F-statistic):           1.10e-30\n",
       "Time:                        18:45:22   Log-Likelihood:                 163.11\n",
       "No. Observations:                  90   AIC:                            -288.2\n",
       "Df Residuals:                      71   BIC:                            -240.7\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           0.4198      0.056      7.542      0.000         0.309     0.531\n",
       "avg_prod_k         -0.4131      0.046     -8.989      0.000        -0.505    -0.321\n",
       "axfin_p            -0.0479      0.103     -0.463      0.645        -0.254     0.158\n",
       "axfin_r             0.0756      0.082      0.922      0.360        -0.088     0.239\n",
       "axhealth           -0.0751      0.054     -1.383      0.171        -0.183     0.033\n",
       "fa                  0.1102      0.115      0.959      0.341        -0.119     0.339\n",
       "finance_pre         0.0115      0.050      0.230      0.819        -0.088     0.111\n",
       "gdp_pc_pp       -1.173e-06   1.33e-06     -0.880      0.382     -3.83e-06  1.49e-06\n",
       "pe                  0.0840      0.011      7.542      0.000         0.062     0.106\n",
       "plgp                0.1091      0.044      2.463      0.016         0.021     0.197\n",
       "prepare_scaleup     0.0696      0.049      1.419      0.160        -0.028     0.167\n",
       "protection          0.0001      0.000      0.362      0.718        -0.001     0.001\n",
       "pv                 -0.0482      0.008     -6.260      0.000        -0.064    -0.033\n",
       "rating              0.0358      0.031      1.145      0.256        -0.027     0.098\n",
       "share1              2.2705      0.345      6.588      0.000         1.583     2.958\n",
       "shew               -0.0184      0.042     -0.441      0.661        -0.102     0.065\n",
       "social_p            0.1889      0.036      5.231      0.000         0.117     0.261\n",
       "social_r            0.1141      0.059      1.942      0.056        -0.003     0.231\n",
       "unemp               0.0594      0.100      0.595      0.554        -0.140     0.258\n",
       "v                  -0.0007      0.043     -0.016      0.988        -0.087     0.086\n",
       "==============================================================================\n",
       "Omnibus:                       15.143   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.824\n",
       "Skew:                           0.833   Prob(JB):                     8.17e-05\n",
       "Kurtosis:                       4.498   Cond. No.                     2.29e+22\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.35e-35. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicative_set = ['avg_prod_k', 'axfin_p', 'axfin_r', 'axhealth', 'fa', 'finance_pre', 'gdp_pc_pp', \n",
    "                   'pe', 'plgp', 'prepare_scaleup', 'protection', 'pv', 'rating', 'share1',\n",
    "                   'shew', 'social_p', 'social_r', 'unemp', 'v']\n",
    "\n",
    "formula =\"resilience ~ \"+\" + \".join(explicative_set) \n",
    "olsmodel=ols(formula,data=df_with_results).fit()\n",
    "\n",
    "a=olsmodel.summary()\n",
    "f = open('regression_against_intpus.csv', 'w')\n",
    "f.write(a.as_csv())\n",
    "f.close()\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
